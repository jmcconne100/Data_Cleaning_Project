{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files, drive\n",
        "\n",
        "def load_csv(method=\"upload\", source=None, concat=False, **read_csv_kwargs):\n",
        "    \"\"\"\n",
        "    Load CSVs in Colab using one of three methods:\n",
        "      - \"upload\": upload from local machine\n",
        "      - \"drive\": read from Google Drive\n",
        "      - \"web\": read from URL(s)\n",
        "\n",
        "    Args:\n",
        "        method: \"upload\" | \"drive\" | \"web\"\n",
        "        source: file path(s) or URL(s); not needed for upload\n",
        "        concat: if True, combine all CSVs into one DataFrame\n",
        "        **read_csv_kwargs: passed to pandas.read_csv()\n",
        "\n",
        "    Returns:\n",
        "        A DataFrame (if concat=True or one file) or dict of {name: DataFrame}\n",
        "\n",
        "    Examples:\n",
        "        df1 = load_csv(\"upload\")\n",
        "\n",
        "        path = \"/content/drive/MyDrive/data/UScomments.csv\"\n",
        "        df2 = load_csv(\"drive\", path)\n",
        "\n",
        "        url = \"https://people.sc.fsu.edu/~jburkardt/data/csv/addresses.csv\"\n",
        "        df3 = load_csv(\"web\", url)\n",
        "    \"\"\"\n",
        "    defaults = {\"on_bad_lines\": \"skip\"}\n",
        "    kwargs = {**defaults, **(read_csv_kwargs or {})}\n",
        "\n",
        "    method = method.lower()\n",
        "    dfs = {}\n",
        "\n",
        "    if method == \"upload\":\n",
        "        uploaded = files.upload()\n",
        "        for name in uploaded.keys():\n",
        "            dfs[name] = pd.read_csv(name, **kwargs)\n",
        "\n",
        "    elif method == \"drive\":\n",
        "        drive.mount(\"/content/drive\", force_remount=False)\n",
        "        if isinstance(source, str):\n",
        "            source = [source]\n",
        "        for path in source:\n",
        "            dfs[path.split(\"/\")[-1]] = pd.read_csv(path, **kwargs)\n",
        "\n",
        "    elif method == \"web\":\n",
        "        if isinstance(source, str):\n",
        "            source = [source]\n",
        "        for url in source:\n",
        "            dfs[url.split(\"/\")[-1]] = pd.read_csv(url, **kwargs)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"method must be one of: 'upload', 'drive', 'web'\")\n",
        "\n",
        "    if concat:\n",
        "        return pd.concat(list(dfs.values()), ignore_index=True)\n",
        "    return dfs if len(dfs) > 1 else next(iter(dfs.values()))"
      ],
      "metadata": {
        "id": "2Q6dTvMLS7eu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "method = \"upload\" # can put in upload, drive, or web\n",
        "# Note if picking drive specify a path and if picking web specify a URL\n",
        "\n",
        "df1 = load_csv(method)\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "xGpOZ9Lx7S5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def basic_sanity_summary(df: pd.DataFrame, top_n: int = 3) -> pd.DataFrame:\n",
        "    n = len(df)\n",
        "    rows = []\n",
        "\n",
        "    for col in df.columns:\n",
        "        s = df[col]\n",
        "        dtype = s.dtype\n",
        "        nulls = int(s.isna().sum())\n",
        "        uniques = int(s.nunique(dropna=True))\n",
        "\n",
        "        blank = 0\n",
        "        whitespace = 0\n",
        "        top_values = \"\"\n",
        "\n",
        "        if pd.api.types.is_object_dtype(s) or pd.api.types.is_string_dtype(s):\n",
        "            s_str = s.astype(\"string\")\n",
        "            blank = int((s_str == \"\").sum(skipna=True))\n",
        "            whitespace = int(s_str.str.match(r\"^\\s+$\", na=False).sum())\n",
        "\n",
        "            vc = s_str.fillna(\"<NA>\").value_counts(dropna=False).head(top_n)\n",
        "            top_values = \"; \".join([f\"{idx} ({cnt})\" for idx, cnt in vc.items()])\n",
        "        else:\n",
        "            vc = s.value_counts(dropna=False).head(top_n)\n",
        "            top_values = \"; \".join([f\"{idx} ({cnt})\" for idx, cnt in vc.items()])\n",
        "\n",
        "        rows.append({\n",
        "            \"column\": col,\n",
        "            \"dtype\": str(dtype),\n",
        "            \"rows\": n,\n",
        "            \"nulls\": nulls,\n",
        "            \"null_%\": round(nulls / n, 4) if n else 0.0,\n",
        "            \"blank_strings\": blank,\n",
        "            \"whitespace_only\": whitespace,\n",
        "            \"unique_values\": uniques,\n",
        "            \"top_values\": top_values\n",
        "        })\n",
        "\n",
        "    summary = pd.DataFrame(rows)\n",
        "    summary = summary.sort_values(\n",
        "        [\"null_%\", \"blank_strings\", \"whitespace_only\"],\n",
        "        ascending=False\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "summary = basic_sanity_summary(df1, top_n=3)\n",
        "summary"
      ],
      "metadata": {
        "id": "-lIKeN_RK5l0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for c in [\"Age\", \"DTIRatio\"]:\n",
        "    print(c, \"dtype:\", df1[c].dtype)\n",
        "    display(df1[c].map(type).value_counts().head(10))"
      ],
      "metadata": {
        "id": "xRAJPpuWwxgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for c in [\"Age\", \"DTIRatio\", \"Income\", \"LoanAmount\", \"InterestRate\", \"CreditScore\", \"NumCreditLines\", \"MonthsEmployed\"]:\n",
        "    if c in df1.columns:\n",
        "        df1[c] = pd.to_numeric(df1[c], errors=\"coerce\")"
      ],
      "metadata": {
        "id": "PrY7MiQrxJvD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAFE_NULL_TOKENS = {\"\", \"null\", \"none\", \"nan\", \"n/a\"}  # exclude \"na\" unless you confirm\n",
        "\n",
        "def clean_blank_like_values(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    obj_cols = df.select_dtypes(include=[\"object\"]).columns\n",
        "\n",
        "    for col in obj_cols:\n",
        "        s = df[col]\n",
        "\n",
        "        # Strip whitespace ONLY for string cells\n",
        "        df[col] = s.map(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "\n",
        "        # Replace safe null tokens (case-insensitive) ONLY for string cells\n",
        "        df[col] = df[col].map(\n",
        "            lambda x: np.nan if isinstance(x, str) and x.strip().lower() in SAFE_NULL_TOKENS else x\n",
        "        )\n",
        "\n",
        "    return df\n",
        "\n",
        "df1 = clean_blank_like_values(df1)\n",
        "\n",
        "display(df1.isna().sum().sort_values(ascending=False).head(20))"
      ],
      "metadata": {
        "id": "fL-1MwedXImO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_cols = df1.select_dtypes(include=[\"number\"]).columns\n",
        "\n",
        "print(\"Numeric columns:\")\n",
        "print(numeric_cols.tolist())\n"
      ],
      "metadata": {
        "id": "ACaY0STyXPuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9777113-aa81-4174-9c2a-58d1dd90d2c0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeric columns:\n",
            "['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed', 'NumCreditLines', 'InterestRate', 'LoanTerm', 'DTIRatio', 'Default']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for c in ['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed', 'NumCreditLines', 'InterestRate', 'LoanTerm', 'DTIRatio', 'Default']:\n",
        "    print(c, \"dtype:\", df1[c].dtype)\n",
        "    display(df1[c].map(type).value_counts().head(10))"
      ],
      "metadata": {
        "id": "7b-Gr4tBXVLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = df1.select_dtypes(include=[\"number\"]).columns\n",
        "null_counts = df1[num_cols].isna().sum().sort_values(ascending=False)\n",
        "\n",
        "display(null_counts[null_counts > 0])"
      ],
      "metadata": {
        "id": "EuSOSh0i6EZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = df1.duplicated().sum()\n",
        "print(\"Duplicate rows:\", duplicates)"
      ],
      "metadata": {
        "id": "25Ub_fObXlak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "before = len(df1)\n",
        "df1 = df1.dropna()\n",
        "after = len(df1)\n",
        "\n",
        "print(\"Rows before:\", before)\n",
        "print(\"Rows remaining:\", after)"
      ],
      "metadata": {
        "id": "cUTMznSXkZJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: drop duplicates\n",
        "df = df1.drop_duplicates()"
      ],
      "metadata": {
        "id": "Lsw2sihg05ni"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_FILE = \"loan_default_cleaned.csv\"\n",
        "\n",
        "df.to_csv(OUTPUT_FILE, index=False)\n",
        "\n",
        "print(\"Saved cleaned file:\", OUTPUT_FILE)\n"
      ],
      "metadata": {
        "id": "q3lxxLDhXwH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(OUTPUT_FILE)"
      ],
      "metadata": {
        "id": "qFxTEyzdmlJI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}